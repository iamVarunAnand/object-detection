{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare PASCAL VOC datasets\n",
    "==============================\n",
    "\n",
    "`Pascal VOC <http://host.robots.ox.ac.uk/pascal/VOC/>`_ is a collection of\n",
    "datasets for object detection. The most commonly combination for\n",
    "benchmarking is using *2007 trainval* and *2012 trainval* for training and *2007\n",
    "test* for validation. This tutorial will walk through the steps of\n",
    "preparing this dataset for GluonCV.\n",
    "\n",
    "![](http://host.robots.ox.ac.uk/pascal/VOC/pascal2.png)\n",
    "\n",
    "\n",
    ".. hint::\n",
    "\n",
    "   You need 8.4 GB disk space to download and extract this dataset. SSD is\n",
    "   preferred over HDD because of its better performance.\n",
    "\n",
    "   The total time to prepare the dataset depends on your Internet speed and disk\n",
    "   performance. For example, it often takes 10 min on AWS EC2 with EBS.\n",
    "\n",
    "Prepare the dataset\n",
    "-------------------\n",
    "\n",
    "We need the following four files from Pascal VOC:\n",
    "\n",
    "+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n",
    "| Filename                                                                                                               | Size   | SHA-1                                    |\n",
    "+========================================================================================================================+========+==========================================+\n",
    "| `VOCtrainval_06-Nov-2007.tar <http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar>`_            | 439 MB | 34ed68851bce2a36e2a223fa52c661d592c66b3c |\n",
    "+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n",
    "| `VOCtest_06-Nov-2007.tar <http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar>`_                    | 430 MB | 41a8d6e12baa5ab18ee7f8f8029b9e11805b4ef1 |\n",
    "+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n",
    "| `VOCtrainval_11-May-2012.tar  <http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar>`_           | 1.9 GB | 4e443f8a2eca6b1dac8a6c57641b67dd40621a49 |\n",
    "+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n",
    "| `benchmark.tgz <http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz>`_   | 1.4 GB | 7129e0a480c2d6afb02b517bb18ac54283bfaa35 |\n",
    "+------------------------------------------------------------------------------------------------------------------------+--------+------------------------------------------+\n",
    "\n",
    "The easiest way to download and unpack these files is to download helper script\n",
    ":download:`pascal_voc.py<../../../scripts/datasets/pascal_voc.py>` and run\n",
    "the following command:\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "    python pascal_voc.py\n",
    "\n",
    "which will automatically download and extract the data into ``~/.mxnet/datasets/voc``.\n",
    "\n",
    "If you already have the above files sitting on your disk,\n",
    "you can set ``--download-dir`` to point to them.\n",
    "For example, assuming the files are saved in ``~/VOCdevkit/``, you can run:\n",
    "\n",
    ".. code-block:: bash\n",
    "\n",
    "   python pascal_voc.py --download-dir ~/VOCdevkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read with GluonCV\n",
    "-----------------\n",
    "\n",
    "Loading images and labels is straight-forward with\n",
    ":py:class:`gluoncv.data.VOCDetection`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from gluoncv import data, utils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_dataset = data.VOCDetection(splits=[(2007, 'trainval'), (2012, 'trainval')])\n",
    "val_dataset = data.VOCDetection(splits=[(2007, 'test')])\n",
    "print('Num of training images:', len(train_dataset))\n",
    "print('Num of validation images:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize one example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_image, train_label = train_dataset[5]\n",
    "print('Image size (height, width, RGB):', train_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take bounding boxes by slice columns from 0 to 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bounding_boxes = train_label[:, :4]\n",
    "print('Num of objects:', bounding_boxes.shape[0])\n",
    "print('Bounding boxes (num_boxes, x_min, y_min, x_max, y_max):\\n',\n",
    "      bounding_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take class ids by slice the 5th column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class_ids = train_label[:, 4:5]\n",
    "print('Class IDs (num_boxes, ):\\n', class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize image, bounding boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "utils.viz.plot_bbox(train_image.asnumpy(), bounding_boxes, scores=None,\n",
    "                    labels=class_ids, class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to use both ``train_dataset`` and ``val_dataset`` for training, we\n",
    "can pass them through data transformations and load with\n",
    ":py:class:`mxnet.gluon.data.DataLoader`, see :download:`train_ssd.py\n",
    "<../../../scripts/detection/ssd/train_ssd.py>` for more information.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
